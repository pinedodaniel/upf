{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# CIFAR-10\n",
        "The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class. It is commonly used for image classification tasks.\n",
        "Here is a list of the classes in the CIFAR-10 dataset:\n",
        "\n",
        "* airplane\n",
        "* automobile\n",
        "* bird\n",
        "* cat\n",
        "* deer\n",
        "* dog\n",
        "* frog\n",
        "* horse\n",
        "* ship\n",
        "* truck\n",
        "\n",
        "These classes represent different objects or animals commonly found in everyday life. The CIFAR-10 dataset is widely used for image classification tasks and serves as a benchmark for evaluating the performance of machine learning and deep learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "uU30uoLhFm5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "#!pip install tensorflow keras numpy matplotlib\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "#history = model.fit(X_train, y_train, epochs=1, batch_size=128, validation_data=(X_test, y_test))\n",
        "model.fit(X_train, y_train, epochs=1, batch_size=128, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Select 20 random images from the testing set\n",
        "indices = np.random.choice(len(X_test), size=20, replace=False)\n",
        "images = X_test[indices]\n",
        "labels_true = np.argmax(y_test[indices], axis=1)\n",
        "\n",
        "# Make predictions for the selected images\n",
        "predictions = model.predict(images)\n",
        "labels_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Plot the images with their predictions\n",
        "fig, axs = plt.subplots(4, 5, figsize=(12, 10))\n",
        "axs = axs.flatten()\n",
        "for i in range(len(indices)):\n",
        "    img = images[i]\n",
        "    label_true = labels_true[i]\n",
        "    label_pred = labels_pred[i]\n",
        "\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].set_title(f\"True: {label_true}\\nPred: {label_pred}\")\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xnyvpM3rEUk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-100\n",
        "\n",
        "The CIFAR-100 dataset is similar to CIFAR-10 but contains 100 classes, each containing 600 images. It is used for more fine-grained image classification tasks."
      ],
      "metadata": {
        "id": "j5wjuhubFkx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "#!pip install tensorflow keras numpy matplotlib\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load the CIFAR-100 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, num_classes=100)\n",
        "y_test = to_categorical(y_test, num_classes=100)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "#history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))\n",
        "model.fit(X_train, y_train, epochs=1, batch_size=128, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Select 20 random images from the testing set\n",
        "indices = np.random.choice(len(X_test), size=20, replace=False)\n",
        "images = X_test[indices]\n",
        "labels_true = np.argmax(y_test[indices], axis=1)\n",
        "\n",
        "# Make predictions for the selected images\n",
        "predictions = model.predict(images)\n",
        "labels_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Plot the images with their predictions\n",
        "fig, axs = plt.subplots(4, 5, figsize=(12, 10))\n",
        "axs = axs.flatten()\n",
        "for i in range(len(indices)):\n",
        "    img = images[i]\n",
        "    label_true = labels_true[i]\n",
        "    label_pred = labels_pred[i]\n",
        "\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].set_title(f\"True: {label_true}\\nPred: {label_pred}\")\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vhe_3buhCbFA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}